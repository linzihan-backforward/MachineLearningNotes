# 人脸识别与神经风格转换（Face recognition and Neural Style Transfer）
***
### 什么是人脸识别？
近几年人脸识别技术发展迅猛，相信所有人都有所耳闻，这一节我们就学习一下如何利用CNN来搭建一个人脸识别的系统。首先，让我们来明确一下目标，人脸识别分为两个阶段，验证（Verification）与识别（Recognition），验证阶段我们需要输入人的图片和人名或者ID，然后输出这张图片是不是这个人。而识别阶段我们只需输入人脸图片，系统会自动输出这个人的名字或ID。这是两个完全不同的概念，因为成本问题，这一节中我们搭建的是一个验证系统，然后用这个验证系统来在一定程度上模拟一个识别系统。下面让我们进入吧。
![](https://i.imgur.com/pdn0MVZ.png)

### 定义相似函数

现在假设我们的问题是，你有一个数据库里面是公司员工的图片，然后你现在拿到了一张新的图片，你要确定这是否是你们公司的人。类比之前的问题，这是一个多分类问题，我们可以用数据库中的图片训练一个带softmax的网络来实现预测，但这里就存在一些问题。首先一个非常棘手的问题是：当你的公司数据库新增加了一个员工时，你要重新训练一遍网络？这显然是一个我们无法接受的问题。还有一个问题是，对于每个人我们可能只有一张数据库照片，这么小的数据量是无法训练出这样的一个CNN的，所以传统的softmax思路是行不通的，我们必须重新寻找一个思路。
我们可以定义一个这样的相似度函数，它以两张图片作为输出，返回他们的相似度，所以对于同一个人，会得到一个很小的值，而对于不同的人，则会得到很大的结果。有了这个函数，我们就可以算出新图片与数据库中所有图片的损失值，如果这里面有一个很小的值的话我们就成功匹配了，没有的话就说明这不是公司的人。
好了，现在我们的问题变为了寻找这样的一个相似函数。

***
### Siamese网络
在2014年的一篇论文提出了这个名叫Siamese的CNN模型，用这个网络可以将一个图片输入对应到一个128维的列向量上，然后两个图片的相似函数就可以定义为列向量的欧式距离。其实这个网络也非常简单，就是去掉传统网络最后的softmax层，用一个128个单元的FC层来结束，这样最后输出的128个数就可以理解为这个图片的编码。
现在了解了网络的基本构成，我们还要知道如何训练这个网络。要想能够反向传播，首先要有损失函数，这里的损失函数比较特殊，是一个三元组函数，我们下一节详细说说。
***

### 三元组损失函数

因为我们最后是要比较所有相似值，从中选出一个最小的作为识别值，所以相似值的绝对大小是没有意义的，有意义的是一个正确识别比一个错误识别的相似值小多少。所以我们学习的关键是让正样本的损失值小于负样本。这样的话我们的损失函数就需要输入一个三元组，分别是要识别图片（Anchor）、正样本（Positive）、负样本（Nagative）
![](https://i.imgur.com/he67Hxn.png)
我们用A代表要识别图片、P代表正样本、N代表负样本。就需要满足以下式子：
d(A,P)+α<=d(A,N)   这里的α是一个正数，用来使正负样本的相似值有一定差距。到这一步，损失函数已经呼之欲出了。
![](https://i.imgur.com/mZwp6mw.gif)
为了让这个损失函数变小，就必须让右边那一项小于0，也就实现了正负样本的差值变大。

有了这个损失函数我们就可以对Siamese网络进行反向传播了，一个完整的人脸识别系统也基本上有了雏形。在代码中可以看到其详细的实现。

下面我们进入风格迁移部分。

### 什么是风格迁移？

把一个图片中的成图要素迁移到另一个图片中，而不改变图片的内容就叫做风格迁移，它是CNN的一个非常有趣的应用，可以让我们自己生成很多富有艺术气息的图片，比如下面这几张图：
![](https://i.imgur.com/XOG9gza.png)
将梵高的抽象风格迁移到普通的风景照上，形成了很多令人眼前一亮的照片。
为了下面的描述方便，我们把内容图片叫做C，风格图片叫做S,生成的新图片叫做G。下面我们就用学过的CNN的知识来完成由C、S生成G的过程。

***
### 深层CNN在学什么？

之前在刚接触CNN的时候我们提到过，不同深度的神经元敏感的信息是不一样的，浅层的神经元只能看到图片的一部分，所以它可能对某个边缘或某个颜色敏感，而深层的神经元会利用之前神经元的信息进行组合，从而对一个物体或一个图形敏感。一个可视化的方法就是对其中的某一个神经元来说，将数据库中的图片输入网络，看哪个图片会让这个神经元得到很高的激活值，那么这个神经元就对这个图片，或这个图片部分感兴趣。有很多相关的论文提出了各种可视化的方法，我们只要知道深度越深，敏感的信息越复杂就行。
![](https://i.imgur.com/d4WuqtD.png)

***
### 代价函数

我们生成新图片G的方法是这样的：首先随机生成一张相应大小的图片，然后假设我们有一个代价函数f(G,C,S)来代表图片G与C、S风格和内容的差值，我们就可以利用梯度下降的方法来更新我们的图片G，最后找到最小值的G就是一个很好的风格迁移图片了。我们的代价函数可以如下定义：
![](https://i.imgur.com/6dqJjwY.gif)
第一项是C、G之间的内容损失函数，第二项是S、G之间的风格损失函数。后面我们会学习这两个函数的详细定义。
α和β是两个超参数，用来调整这两个损失的比例。
***
### 内容代价函数

如上面说的，CNN中的神经元会对图片中的某些内容敏感，所以其一些层的输出值就代表了整张图片的内容，为了不过分关注细节，也不是对整张图考虑，所以我们选择的时候要选既不深也不浅的一层的输出值作为内容的代表，假设我们选择的是第l层，那么这个内容损失函数就可以这么定义：
![](https://i.imgur.com/AvgTURm.gif)
用同一层对两个图片输出值的欧式距离作为损失函数。

***
### 风格损失函数

怎样来描述一个图片的风格呢？一个方法是用同一层两个神经元输出值的关系来描述风格。两个神经元如果总是同时最大或同时最小，那么我们说他们是正相关的，两个神经元正相关，说明这张图片的这两个特征总是同时出现，这在一定程度上就代表了这张图片的风格。同理我们选择一个恰当的层，然后计算这一层上所有神经元之间的相关程度。注意，这里一个神经元的输出是一个矩阵，要计算两个神经元的相关度，就要把相应位置的值相乘后，将所有值相加，得到整体的相关度。如果这一层有n个神经元，我们就得到一个n×n的相关度矩阵。这样我们的风格损失函数定义如下：
![](https://i.imgur.com/TYk3fYi.gif)
两个矩阵的欧式距离乘上一个归一化常数得到整个损失函数。

现在我们已经拥有了整个代价函数了，赶紧用它来进行训练，得到一个属于自己图图片吧。